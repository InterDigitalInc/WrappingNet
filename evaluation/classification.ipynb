{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrappingnet.utils as utils\n",
    "from wrappingnet.dataloaders import manifold40_dset\n",
    "from wrappingnet.models import WrappingNet_sphere_LC, WrappingNet_global_basesup3\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = manifold40_dset(root='./datasets/Manifold40', train=True)\n",
    "dset_test = manifold40_dset(root='./datasets/Manifold40', train=False)\n",
    "len(dset_train), len(dset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loop 3 times\"\"\"\n",
    "params = {'loss_func':'MSL2', 'dset':'manifold40', 'latent_dim':512, 'extra':'global_basesup3'}\n",
    "model = WrappingNet_global_basesup3(input_dim=7, feature_dim=params['latent_dim'], num_loop=3)\n",
    "saved = torch.load(f\"trained/MeshAE_{params['loss_func']}_{params['dset']}_d{params['latent_dim']}{params['extra']}.ckpt\", map_location='cpu')\n",
    "model.load_state_dict(saved)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loop 3 times\"\"\"\n",
    "params = {'loss_func':'MSL2', 'dset':'manifold40', 'latent_dim':512, 'extra':'LC'}\n",
    "model = WrappingNet_sphere_LC(input_dim=7, feature_dim=params['latent_dim'], num_loop=3)\n",
    "saved = torch.load(f\"trained/MeshAE_{params['loss_func']}_{params['dset']}_d{params['latent_dim']}{params['extra']}.ckpt\", map_location='cpu')\n",
    "model.load_state_dict(saved)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "z_train = []\n",
    "for i, mesh in tqdm.tqdm(enumerate(dset_train), total=len(dset_train)):\n",
    "    mesh = mesh.to(device)\n",
    "    with torch.no_grad():\n",
    "        mesh.pos = utils.normalize_pos(mesh.pos)\n",
    "        face_base, features = model.encoder(mesh.pos, mesh.face.T)\n",
    "        features = model.mlp(features)\n",
    "        latent_code = torch.max(features, dim=0)[0].unsqueeze(0) \n",
    "        latent_code = model.mlp2(latent_code).squeeze() \n",
    "    z_train.append(latent_code)\n",
    "z_train = torch.stack(z_train).cpu().numpy()\n",
    "\n",
    "z_test = []\n",
    "for i, mesh in tqdm.tqdm(enumerate(dset_test), total=len(dset_test)):\n",
    "    mesh = mesh.to(device)\n",
    "    with torch.no_grad():\n",
    "        face_base, features = model.encoder(mesh.pos, mesh.face.T)\n",
    "        features = model.mlp(features)\n",
    "        latent_code = torch.max(features, dim=0)[0].unsqueeze(0) \n",
    "        latent_code = model.mlp2(latent_code).squeeze() \n",
    "    z_test.append(latent_code)\n",
    "z_test = torch.stack(z_test).cpu().numpy()\n",
    "\n",
    "z_total = np.concatenate((z_train, z_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.repeat(np.arange(30), 16)\n",
    "labels_test = np.repeat(np.arange(30), 4)\n",
    "labels_train = np.repeat(np.arange(30), 200)\n",
    "labels_test = np.repeat(np.arange(30), 200)\n",
    "labels_total = np.concatenate((labels_train, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "info = pd.read_csv('./evaluation/metadata_modelnet40.csv')\n",
    "test_idx = np.where(info['split']=='test')\n",
    "test_labels  = info['class'].to_numpy()[test_idx]\n",
    "train_idx = np.where(info['split']=='train')\n",
    "train_labels = info['class'].to_numpy()[train_idx]\n",
    "x = list(set(test_labels))\n",
    "dic = dict(zip(x, list(range(1,len(x)+1))))\n",
    "labels_test =[dic[v] for v in test_labels]\n",
    "x = list(set(train_labels))\n",
    "dic = dict(zip(x, list(range(1,len(x)+1))))\n",
    "labels_train =[dic[v] for v in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn10_classes = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "dir = './datasets/Manifold40/raw'\n",
    "classes = sorted(os.listdir(dir))\n",
    "n = 0\n",
    "\n",
    "train_labels = []\n",
    "i_train = []\n",
    "cntr = 0\n",
    "cntr_cls = 0\n",
    "for i, cls in enumerate(classes):\n",
    "    n = len(os.listdir(os.path.join(dir, cls, 'train')))\n",
    "    if cls in mn10_classes:\n",
    "        train_labels.extend([cntr_cls]*n)\n",
    "        cntr_cls += 1\n",
    "        i_train.extend(list(range(cntr, cntr+n)))\n",
    "    cntr += n\n",
    "\n",
    "test_labels = []\n",
    "i_test = []\n",
    "cntr = 0\n",
    "cntr_cls = 0\n",
    "for i, cls in enumerate(classes):\n",
    "    n = len(os.listdir(os.path.join(dir, cls, 'test')))\n",
    "    if cls in mn10_classes:\n",
    "        test_labels.extend([cntr_cls]*n)\n",
    "        cntr_cls += 1\n",
    "        i_test.extend(list(range(cntr, cntr+n)))\n",
    "    cntr += n\n",
    "\n",
    "len(train_labels), len(test_labels)\n",
    "\n",
    "z_test10 = z_test[i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "z = tsne.fit_transform(z_test[:])\n",
    "# z_tsne = tsne.fit(z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'lines.linewidth':1})\n",
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['legend.framealpha'] = None\n",
    "plt.rcParams['legend.edgecolor'] = 'inherit'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['mathtext.rm'] = 'serif'\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker \n",
    "mn10_classes = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night', 'sofa', 'table', 'toilet']\n",
    "plt.figure()\n",
    "plt.locator_params(nbins=10)\n",
    "plt.scatter(z[:,0], z[:,1], c=labels_test, cmap='twilight')\n",
    "plt.grid(linestyle='dashed')\n",
    "cbar = plt.colorbar()\n",
    "tick_locator = ticker.MaxNLocator(nbins=15)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "# cbar.ax.set_yticklabels(dic.keys()) \n",
    "# plt.savefig('plots/TSNE_Manifold40_HMN_level0.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pccai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "183e7f806bcbb61d663dad6aba9fc871a48483ac915196e6d61b7057aa352d22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
